graphics.off();
rm(list=ls());
directory = "C:/Users/LooiXIV\Desktop/Historical Waterleve Data - Oswego - 1933 to 1950"
setwd(directory)
graphics.off();
rm(list=ls());
directory = "C:/Users/LooiXIV\Desktop/Historical Waterleve Data - Oswego - 1933 to 1950"
setwd(directory)
library(RCurl)
#Site.WLname = "Alex Bay"
Site.WLname = "Oswego"
#Site.WLname = "Cape Vincent"
#site_no = "8311062" # Alexandria Bay
site_no = "9052030" # Oswego NY
#site_no = "9052000" # Cape Vincenet, NY
#start_date = "20130101"
#end_date = "20131231"
start = as.Date("1930/01/01")
end = as.Date("1950/12/31")
dates = seq.Date(start, end, by = "year")
dates = as.character(dates)
interval = "daily_mean"
#interval = "hourly_height"
TZ = "LST" # goes with the "daily_mean" data set
#TZ = "GMT" # goes with the "hourly_height" data set
getWLcsv.NOAA = function(site_no, start_date, end_date, TimeZone){
web = paste("http://tidesandcurrents.noaa.gov/api/datagetter?product=",interval ,
"&application=NOS.COOPS.TAC.WL&station=",
site_no, "&begin_date=",
start_date, "&end_date=", end_date,
"&datum=IGLD&units=metric&time_zone=",TimeZone,"&format=csv", sep = "")
x = getURL(web)
output = read.csv(textConnection(x))
return(output)
}
for(d in 1:length(dates)){
begin = paste(substr(dates[d], 1, 4), substr(dates[d], 6, 7), substr(dates[d], 9, 10), sep = "")
end = paste(substr(dates[d], 1, 4), "12", "31", sep = "")
data = getWLcsv.NOAA(site_no, begin, end, TZ)
Year = substr(dates[d], 1, 4)
name.file = paste("NOAA ", Site.WLname, " ", interval, " WL", "_", Year, ".csv", sep = "")
write.csv(data, file = name.file)
}
directory = "C:/Users/LooiXIV/Desktop/Historical Waterleve Data - Oswego - 1933 to 1950"
setwd(directory)
library(RCurl)
install.packages("RCurl")
graphics.off();
rm(list=ls());
directory = "C:/Users/LooiXIV/Desktop/Historical Waterleve Data - Oswego - 1933 to 1950"
setwd(directory)
library(RCurl)
#Site.WLname = "Alex Bay"
Site.WLname = "Oswego"
#Site.WLname = "Cape Vincent"
#site_no = "8311062" # Alexandria Bay
site_no = "9052030" # Oswego NY
#site_no = "9052000" # Cape Vincenet, NY
#start_date = "20130101"
#end_date = "20131231"
start = as.Date("1930/01/01")
end = as.Date("1950/12/31")
dates = seq.Date(start, end, by = "year")
dates = as.character(dates)
interval = "daily_mean"
#interval = "hourly_height"
TZ = "LST" # goes with the "daily_mean" data set
#TZ = "GMT" # goes with the "hourly_height" data set
getWLcsv.NOAA = function(site_no, start_date, end_date, TimeZone){
web = paste("http://tidesandcurrents.noaa.gov/api/datagetter?product=",interval ,
"&application=NOS.COOPS.TAC.WL&station=",
site_no, "&begin_date=",
start_date, "&end_date=", end_date,
"&datum=IGLD&units=metric&time_zone=",TimeZone,"&format=csv", sep = "")
x = getURL(web)
output = read.csv(textConnection(x))
return(output)
}
for(d in 1:length(dates)){
begin = paste(substr(dates[d], 1, 4), substr(dates[d], 6, 7), substr(dates[d], 9, 10), sep = "")
end = paste(substr(dates[d], 1, 4), "12", "31", sep = "")
data = getWLcsv.NOAA(site_no, begin, end, TZ)
Year = substr(dates[d], 1, 4)
name.file = paste("NOAA ", Site.WLname, " ", interval, " WL", "_", Year, ".csv", sep = "")
write.csv(data, file = name.file)
}
?write.table
graphics.off();
rm(list=ls());
directory = "C:/Users/LooiXIV/Desktop/Historical Waterleve Data - Oswego - 1933 to 1950"
setwd(directory)
library(RCurl)
#Site.WLname = "Alex Bay"
Site.WLname = "Oswego"
#Site.WLname = "Cape Vincent"
#site_no = "8311062" # Alexandria Bay
site_no = "9052030" # Oswego NY
#site_no = "9052000" # Cape Vincenet, NY
#start_date = "20130101"
#end_date = "20131231"
start = as.Date("1930/01/01")
end = as.Date("1950/12/31")
dates = seq.Date(start, end, by = "year")
dates = as.character(dates)
interval = "daily_mean"
#interval = "hourly_height"
TZ = "LST" # goes with the "daily_mean" data set
#TZ = "GMT" # goes with the "hourly_height" data set
getWLcsv.NOAA = function(site_no, start_date, end_date, TimeZone){
web = paste("http://tidesandcurrents.noaa.gov/api/datagetter?product=",interval ,
"&application=NOS.COOPS.TAC.WL&station=",
site_no, "&begin_date=",
start_date, "&end_date=", end_date,
"&datum=IGLD&units=metric&time_zone=",TimeZone,"&format=csv", sep = "")
x = getURL(web)
output = read.csv(textConnection(x))
return(output)
}
for(d in 1:length(dates)){
begin = paste(substr(dates[d], 1, 4), substr(dates[d], 6, 7), substr(dates[d], 9, 10), sep = "")
end = paste(substr(dates[d], 1, 4), "12", "31", sep = "")
data = getWLcsv.NOAA(site_no, begin, end, TZ)
Year = substr(dates[d], 1, 4)
name.file = paste("NOAA ", Site.WLname, " ", interval, " WL", "_", Year, ".csv", sep = "")
write.table(data, file = name.file, row.names = F)
}
graphics.off();
rm(list=ls());
directory = "C:/Users/LooiXIV/Desktop/Historical Waterleve Data - Oswego - 1933 to 1950"
setwd(directory)
library(RCurl)
#Site.WLname = "Alex Bay"
Site.WLname = "Oswego"
#Site.WLname = "Cape Vincent"
#site_no = "8311062" # Alexandria Bay
site_no = "9052030" # Oswego NY
#site_no = "9052000" # Cape Vincenet, NY
#start_date = "20130101"
#end_date = "20131231"
start = as.Date("1930/01/01")
end = as.Date("1950/12/31")
dates = seq.Date(start, end, by = "year")
dates = as.character(dates)
interval = "daily_mean"
#interval = "hourly_height"
TZ = "LST" # goes with the "daily_mean" data set
#TZ = "GMT" # goes with the "hourly_height" data set
getWLcsv.NOAA = function(site_no, start_date, end_date, TimeZone){
web = paste("http://tidesandcurrents.noaa.gov/api/datagetter?product=",interval ,
"&application=NOS.COOPS.TAC.WL&station=",
site_no, "&begin_date=",
start_date, "&end_date=", end_date,
"&datum=IGLD&units=metric&time_zone=",TimeZone,"&format=csv", sep = "")
x = getURL(web)
output = read.csv(textConnection(x))
return(output)
}
for(d in 1:length(dates)){
begin = paste(substr(dates[d], 1, 4), substr(dates[d], 6, 7), substr(dates[d], 9, 10), sep = "")
end = paste(substr(dates[d], 1, 4), "12", "31", sep = "")
data = getWLcsv.NOAA(site_no, begin, end, TZ)
Year = substr(dates[d], 1, 4)
name.file = paste("NOAA ", Site.WLname, " ", interval, " WL", "_", Year, ".csv", sep = "")
write.table(data, file = name.file, row.names = F, sep = ",")
}
begin
getWLcsv.NOAA(site_no, begin, end, TZ)
list.files()
list.files(pattern = "daily_mean")
list.files(pattern = "daily_mean")
tot.years
tot.years = First.Year - Last.Year + 1
First.Year = 1930
Last.Year = 1950
tot.years = First.Year - Last.Year + 1
tot.years
tot.years = Last.Year- First.Year + 1
tot.years
tot.files = length(all.files)
# Consolidate daily water level data and format it correctly
graphics.off
rm(list = ls())
Dir = "C:/Users/LooiXIV/Desktop/Historical Waterleve Data - Oswego - 1933 to 1950"
setwd(Dir)
# Read in WL data
First.Year = 1930
Last.Year = 1950
tot.years = Last.Year- First.Year + 1
all.files = list.files(pattern = "daily_mean")
tot.files = length(all.files)
for (y in 1:tot.years){
}
tot.files
tot.years
?read.table
y = 1
read.table(all.files[y], header = T, sep = ",")
WL.data = read.table(all.files[y], header = T, sep = ",")
Date = substring(WL.data$Date.Time, 1, 10)
Date
seq.Date(1930, 1950, by = "day")
seq.POSIXt(first.date, last.date)
first.date = paste(First.Year, "-01-01", sep = "")
last.date = paste(Last.Year, "-12-31", sep = "")
seq.POSIXt(first.date, last.date)
first.date = as.POSIXlt(paste(First.Year, "-01-01", sep = ""))
first.date
last.date = as.POSIXlt(paste(Last.Year, "-12-31", sep = ""))
seq.POSIXt(first.date, last.date)
?seq.POSIXt
seq.POSIXt(first.date, last.date, by = "day")
Date
WL = raw.data$Water.Level
for (y in 1:tot.years){
raw.data = read.table(all.files[y], header = T, sep = ",")
Date = substring(raw.data$Date.Time, 1, 10)
WL = raw.data$Water.Level
}
WL
Date
seq.POSIXt(first.date, last.date, by = "day")
length(seq.POSIXt(first.date, last.date, by = "day"))
graphics.off();
rm(list=ls());
directory = "C:/Users/LooiXIV/Desktop"
#Site.WLname = "Alex Bay"
Site.WLname = "Oswego"
#Site.WLname = "Cape Vincent"
# you will need the correct site number for the site you wish to download
# data from. you can find this number on the NOAA, Tides and currents site.
#site_no = "8311062" # Alexandria Bay
site_no = "9052030" # Oswego NY
#site_no = "9052000" # Cape Vincenet, NY
# Time period/range of years to download data.
start.year = 1900
end.year = 2014
time.step = "daily"
#time.step = "hourly"
###################################################
#
#
###################################################
S.date = paste(start.year, "/01/01", sep = "")
E.date = paste(end.year, "/12/31", sep = "")
start = as.Date(S.date)
end = as.Date(E.date)
# Create a new folder to house the downloaded data
# Create an intuitive folder name
dir.newWL = paste(Site.WLname, " ",
"StaNum ", site_no, " ",
start.year, "-", end.year, sep = "")
# Set the work directory where the newly created folder will go
setwd(directory)
# Create the new folder
dir.create(dir.newWL)
# Access the new folder where our newly downloaded data will go
New.Dir = paste(directory, "/", dir.newWL, sep = "")
setwd(New.Dir)
# Load the RCurl library
library(RCurl)
# Create a sequence to dates to be used in
dates = seq.Date(start, end, by = "year")
dates = as.character(dates)
if (time.step == "daily") {
interval = "daily_mean"
TZ = "LST" # goes with the "daily_mean" data set
} else if(time.step == "hourly") {
interval = "hourly_height"
TZ = "GMT" # goes with the "hourly_height" data set
}
# Create a function that can be called to download the NOAA data
# Takes in four variables needed to access the NOAA data properly
# Site number, the start date, the end data, and the time zone.
getWLcsv.NOAA = function(site_no, start_date, end_date, TimeZone){
# Create the URL to access the downloaded data
web = paste("http://tidesandcurrents.noaa.gov/api/datagetter?product=",interval ,
"&application=NOS.COOPS.TAC.WL&station=",
site_no, "&begin_date=",
start_date, "&end_date=", end_date,
"&datum=IGLD&units=metric&time_zone=",TimeZone,"&format=csv", sep = "")
# use the getURL function to access the web page via R
x = getURL(web)
# Read the data into R as a csv file
output = read.csv(textConnection(x))
return(output)
}
# This loop cycles through all years in the range selected from "start.year" to end.year
for(d in 1:length(dates)){
# Beginning of the year
begin = paste(substr(dates[d], 1, 4),
substr(dates[d], 6, 7),
substr(dates[d], 9, 10), sep = "")
# end of the year
end = paste(substr(dates[d], 1, 4), "12", "31", sep = "")
# access the function
data = getWLcsv.NOAA(site_no, begin, end, TZ)
Year = substr(dates[d], 1, 4)
name.file = paste("NOAA ", Site.WLname, " ", interval, " WL", "_", Year, ".csv", sep = "")
write.table(data, file = name.file, row.names = F, sep = ",")
}
directory = "C:/Users/LooiXIV/Desktop"
setwd(directory)
getwd()
graphics.off();
rm(list=ls());
directory = "C:/Users/Alex Looi/Desktop"
#Site.WLname = "Alex Bay"
Site.WLname = "Oswego"
#Site.WLname = "Cape Vincent"
# you will need the correct site number for the site you wish to download
# data from. you can find this number on the NOAA, Tides and currents site.
#site_no = "8311062" # Alexandria Bay
site_no = "9052030" # Oswego NY
#site_no = "9052000" # Cape Vincenet, NY
# Time period/range of years to download data.
start.year = 1900
end.year = 2014
time.step = "daily"
#time.step = "hourly"
###################################################
#
#
###################################################
S.date = paste(start.year, "/01/01", sep = "")
E.date = paste(end.year, "/12/31", sep = "")
start = as.Date(S.date)
end = as.Date(E.date)
# Create a new folder to house the downloaded data
# Create an intuitive folder name
dir.newWL = paste(Site.WLname, " ",
"StaNum ", site_no, " ",
start.year, "-", end.year, sep = "")
# Set the work directory where the newly created folder will go
setwd(directory)
# Create the new folder
dir.create(dir.newWL)
# Access the new folder where our newly downloaded data will go
New.Dir = paste(directory, "/", dir.newWL, sep = "")
setwd(New.Dir)
# Load the RCurl library
library(RCurl)
# Create a sequence to dates to be used in
dates = seq.Date(start, end, by = "year")
dates = as.character(dates)
if (time.step == "daily") {
interval = "daily_mean"
TZ = "LST" # goes with the "daily_mean" data set
} else if(time.step == "hourly") {
interval = "hourly_height"
TZ = "GMT" # goes with the "hourly_height" data set
}
# Create a function that can be called to download the NOAA data
# Takes in four variables needed to access the NOAA data properly
# Site number, the start date, the end data, and the time zone.
getWLcsv.NOAA = function(site_no, start_date, end_date, TimeZone){
# Create the URL to access the downloaded data
web = paste("http://tidesandcurrents.noaa.gov/api/datagetter?product=",interval ,
"&application=NOS.COOPS.TAC.WL&station=",
site_no, "&begin_date=",
start_date, "&end_date=", end_date,
"&datum=IGLD&units=metric&time_zone=",TimeZone,"&format=csv", sep = "")
# use the getURL function to access the web page via R
x = getURL(web)
# Read the data into R as a csv file
output = read.csv(textConnection(x))
return(output)
}
# This loop cycles through all years in the range selected from "start.year" to end.year
for(d in 1:length(dates)){
# Beginning of the year
begin = paste(substr(dates[d], 1, 4),
substr(dates[d], 6, 7),
substr(dates[d], 9, 10), sep = "")
# end of the year
end = paste(substr(dates[d], 1, 4), "12", "31", sep = "")
# access the function
data = getWLcsv.NOAA(site_no, begin, end, TZ)
Year = substr(dates[d], 1, 4)
name.file = paste("NOAA ", Site.WLname, " ", interval, " WL", "_", Year, ".csv", sep = "")
write.table(data, file = name.file, row.names = F, sep = ",")
}
library(RCurl)
install.packages("RCurl")
graphics.off();
rm(list=ls());
directory = "C:/Users/Alex Looi/Desktop"
#Site.WLname = "Alex Bay"
Site.WLname = "Oswego"
#Site.WLname = "Cape Vincent"
# you will need the correct site number for the site you wish to download
# data from. you can find this number on the NOAA, Tides and currents site.
#site_no = "8311062" # Alexandria Bay
site_no = "9052030" # Oswego NY
#site_no = "9052000" # Cape Vincenet, NY
# Time period/range of years to download data.
start.year = 1900
end.year = 2014
time.step = "daily"
#time.step = "hourly"
###################################################
#
#
###################################################
S.date = paste(start.year, "/01/01", sep = "")
E.date = paste(end.year, "/12/31", sep = "")
start = as.Date(S.date)
end = as.Date(E.date)
# Create a new folder to house the downloaded data
# Create an intuitive folder name
dir.newWL = paste(Site.WLname, " ",
"StaNum ", site_no, " ",
start.year, "-", end.year, sep = "")
# Set the work directory where the newly created folder will go
setwd(directory)
# Create the new folder
dir.create(dir.newWL)
# Access the new folder where our newly downloaded data will go
New.Dir = paste(directory, "/", dir.newWL, sep = "")
setwd(New.Dir)
# Load the RCurl library
library(RCurl)
# Create a sequence to dates to be used in
dates = seq.Date(start, end, by = "year")
dates = as.character(dates)
if (time.step == "daily") {
interval = "daily_mean"
TZ = "LST" # goes with the "daily_mean" data set
} else if(time.step == "hourly") {
interval = "hourly_height"
TZ = "GMT" # goes with the "hourly_height" data set
}
# Create a function that can be called to download the NOAA data
# Takes in four variables needed to access the NOAA data properly
# Site number, the start date, the end data, and the time zone.
getWLcsv.NOAA = function(site_no, start_date, end_date, TimeZone){
# Create the URL to access the downloaded data
web = paste("http://tidesandcurrents.noaa.gov/api/datagetter?product=",interval ,
"&application=NOS.COOPS.TAC.WL&station=",
site_no, "&begin_date=",
start_date, "&end_date=", end_date,
"&datum=IGLD&units=metric&time_zone=",TimeZone,"&format=csv", sep = "")
# use the getURL function to access the web page via R
x = getURL(web)
# Read the data into R as a csv file
output = read.csv(textConnection(x))
return(output)
}
# This loop cycles through all years in the range selected from "start.year" to end.year
for(d in 1:length(dates)){
# Beginning of the year
begin = paste(substr(dates[d], 1, 4),
substr(dates[d], 6, 7),
substr(dates[d], 9, 10), sep = "")
# end of the year
end = paste(substr(dates[d], 1, 4), "12", "31", sep = "")
# access the function
data = getWLcsv.NOAA(site_no, begin, end, TZ)
Year = substr(dates[d], 1, 4)
name.file = paste("NOAA ", Site.WLname, " ", interval, " WL", "_", Year, ".csv", sep = "")
write.table(data, file = name.file, row.names = F, sep = ",")
}
